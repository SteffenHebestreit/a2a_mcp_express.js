# Server Configuration
PORT=3000
AGENT_BASE_URL=http://localhost:3000
AGENT_NAME=MyLangchainNodeAgentMCP
AGENT_DESCRIPTION=A helpful agent built with Langchain and Node.js using MCP.

# MCP Configuration
MCP_SERVER_URL=http://mcp-mock:9000/mcp

# LLM Configuration
# Provider options: 'openai', 'ollama', 'anthropic'
LLM_PROVIDER=openai

# OpenAI Configuration (used when LLM_PROVIDER=openai)
OPENAI_API_KEY=your-openai-api-key-here

# Ollama Configuration (used when LLM_PROVIDER=ollama)
OLLAMA_BASE_URL=http://localhost:11434
# For Docker, use: OLLAMA_BASE_URL=http://host.docker.internal:11434

# Anthropic Configuration (used when LLM_PROVIDER=anthropic)
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Shared LLM Configuration
MODEL=gpt-4o-mini
# For Ollama, use models like: llama3, mistral, etc.
# For Anthropic, use models like: claude-3-opus-20240229
TEMPERATURE=0.7

# Memory Configuration
# Options: 'memory', 'redis'
MEMORY_TYPE=memory
# Redis URL (required if MEMORY_TYPE=redis)
# For local development: REDIS_URL=redis://localhost:6379
# For Docker: REDIS_URL=redis://redis:6379
# TTL for conversation history in seconds (default: 24 hours)
MEMORY_CHAT_HISTORY_TTL=86400

# A2A Protocol Version
A2A_VERSION=1.0

# Docker hostname for Traefik (extract from AGENT_BASE_URL or set manually)
AGENT_BASE_URL_HOSTNAME=agent.localhost
